{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model\n",
      "load linear output model\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import numpy as np\n",
    "from utils import *\n",
    "\n",
    "import keras\n",
    "from keras.applications.inception_v3 import inception_v3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "K.clear_session()\n",
    "#model = inception_v3.InceptionV3(input_shape=(299,299,3),weights=\"imagenet\")\n",
    "print(\"load model\")\n",
    "model = VGG16(input_shape=(224,224,3),weights=\"imagenet\")\n",
    "print(\"load linear output model\")\n",
    "lmodel = linearize_activation(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#https://github.com/tensorflow/lucid/blob/master/lucid/optvis/transform.py\n",
    "\n",
    "def jitter(d, seed=None):\n",
    "    def inner(t_image):\n",
    "        t_image = tf.convert_to_tensor(t_image, preferred_dtype=tf.float32)\n",
    "        t_shp = tf.shape(t_image)\n",
    "        crop_shape = tf.concat([t_shp[:-3], t_shp[-3:-1] - d, t_shp[-1:]], 0)\n",
    "        crop = tf.random_crop(t_image, crop_shape, seed=seed)\n",
    "        shp = t_image.get_shape().as_list()\n",
    "        mid_shp_changed = [\n",
    "            shp[-3] - d if shp[-3] is not None else None,\n",
    "            shp[-2] - d if shp[-3] is not None else None,\n",
    "        ]\n",
    "        crop.set_shape(shp[:-3] + mid_shp_changed + shp[-1:])\n",
    "        return crop\n",
    "\n",
    "    return inner\n",
    "\n",
    "def pad(w, mode=\"REFLECT\", constant_value=0.5):\n",
    "    def inner(t_image):\n",
    "        if constant_value == \"uniform\":\n",
    "            constant_value_ = tf.random_uniform([], 0, 1)\n",
    "        else:\n",
    "            constant_value_ = constant_value\n",
    "        return tf.pad(\n",
    "            t_image,\n",
    "            [(0, 0), (w, w), (w, w), (0, 0)],\n",
    "            mode=mode,\n",
    "            constant_values=constant_value_,\n",
    "        )\n",
    "\n",
    "    return inner\n",
    "\n",
    "\n",
    "# def random_scale(scales, seed=None):\n",
    "#   def inner(t):\n",
    "#     t = tf.convert_to_tensor(t, preferred_dtype=\"float32\")\n",
    "#     scale = _rand_select(scales, seed=seed)\n",
    "#     shp = tf.shape(t)\n",
    "#     scale_shape = tf.concat(\n",
    "#         [shp[:-3], tf.cast(scale * tf.cast(shp[-3:-1], \"float32\"), \"int32\"), shp[-1:]], 0)\n",
    "#     return resize_bilinear_nd(t, scale_shape)\n",
    "#   return inner\n",
    "\n",
    "# 2D only version\n",
    "def random_scale(scales, seed=None):\n",
    "    def inner(t):\n",
    "        t = tf.convert_to_tensor(t, preferred_dtype=tf.float32)\n",
    "        scale = _rand_select(scales, seed=seed)\n",
    "        shp = tf.shape(t)\n",
    "        scale_shape = tf.cast(scale * tf.cast(shp[-3:-1], \"float32\"), \"int32\")\n",
    "        return tf.image.resize_bilinear(t, scale_shape)\n",
    "\n",
    "    return inner\n",
    "\n",
    "\n",
    "def random_rotate(angles, units=\"degrees\", seed=None):\n",
    "    def inner(t):\n",
    "        t = tf.convert_to_tensor(t, preferred_dtype=tf.float32)\n",
    "        angle = _rand_select(angles, seed=seed)\n",
    "        angle = _angle2rads(angle, units)\n",
    "        return tf.contrib.image.rotate(t, angle)\n",
    "\n",
    "    return inner\n",
    "\n",
    "\n",
    "def normalize_gradient(grad_scales=None):\n",
    "\n",
    "    if grad_scales is not None:\n",
    "        grad_scales = np.float32(grad_scales)\n",
    "\n",
    "    op_name = \"NormalizeGrad_\" + str(uuid.uuid4())\n",
    "\n",
    "    @tf.RegisterGradient(op_name)\n",
    "    def _NormalizeGrad(op, grad):\n",
    "        grad_norm = tf.sqrt(tf.reduce_sum(grad ** 2, [1, 2, 3], keepdims=True))\n",
    "        if grad_scales is not None:\n",
    "            grad *= grad_scales[:, None, None, None]\n",
    "        return grad / grad_norm\n",
    "\n",
    "    def inner(x):\n",
    "        with x.graph.gradient_override_map({\"Identity\": op_name}):\n",
    "            x = tf.identity(x)\n",
    "        return x\n",
    "\n",
    "    return inner\n",
    "\n",
    "def compose(transforms):\n",
    "    def inner(x):\n",
    "        for transform in transforms:\n",
    "            x = transform(x)\n",
    "        return x\n",
    "\n",
    "    return inner\n",
    "\n",
    "def collapse_alpha_random(sd=0.5):\n",
    "    def inner(t_image):\n",
    "        rgb, a = t_image[..., :3], t_image[..., 3:4]\n",
    "        rgb_shape = rgb.get_shape().as_list()\n",
    "        rand_img = param.random.image_sample(rgb_shape, sd=sd)\n",
    "        return a * rgb + (1 - a) * rand_img\n",
    "\n",
    "    return inner\n",
    "\n",
    "\n",
    "def _rand_select(xs, seed=None):\n",
    "    rand_n = tf.random_uniform((), 0, len(xs), \"int32\", seed=seed)\n",
    "    return tf.constant(xs)[rand_n]\n",
    "\n",
    "\n",
    "def _angle2rads(angle, units):\n",
    "    angle = tf.cast(angle, \"float32\")\n",
    "    if units.lower() == \"degrees\":\n",
    "        angle = 3.14 * angle / 180.\n",
    "    elif units.lower() in [\"radians\", \"rads\", \"rad\"]:\n",
    "        angle = angle\n",
    "    return angle\n",
    "\n",
    "\n",
    "standard_transforms = [\n",
    "    pad(12, mode=\"constant\", constant_value=.5),\n",
    "    jitter(8),\n",
    "    random_scale([1 + (i - 5) / 50. for i in range(11)]),\n",
    "    random_rotate(list(range(-10, 11)) + 5 * [0]),\n",
    "    jitter(4),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jitter(t_image,d, seed=None):\n",
    "    #t_image = tf.convert_to_tensor(t_image, preferred_dtype=tf.float32)\n",
    "    t_shp = tf.shape(t_image)\n",
    "    crop_shape = tf.concat([t_shp[:-3], t_shp[-3:-1] - d, t_shp[-1:]], 0)\n",
    "    crop = tf.random_crop(t_image, crop_shape, seed=seed)\n",
    "    shp = t_image.get_shape().as_list()\n",
    "    mid_shp_changed = [\n",
    "        shp[-3] - d if shp[-3] is not None else None,\n",
    "        shp[-2] - d if shp[-3] is not None else None,\n",
    "    ]\n",
    "    crop.set_shape(shp[:-3] + mid_shp_changed + shp[-1:])\n",
    "    return crop\n",
    "\n",
    "def pad(t_image,w, mode=\"REFLECT\", constant_value=0.5):\n",
    "    if constant_value == \"uniform\":\n",
    "        constant_value_ = tf.random_uniform([], 0, 1)\n",
    "    else:\n",
    "        constant_value_ = constant_value\n",
    "    return tf.pad(\n",
    "        t_image,\n",
    "        [(0, 0), (w, w), (w, w), (0, 0)],\n",
    "        mode=mode,\n",
    "        constant_values=constant_value_,\n",
    "    )\n",
    "\n",
    "def pseudo(t_image,w=0, constant_value=0.5):\n",
    "    return tf.pad(\n",
    "        t_image,\n",
    "        [(0, 0), (w, w), (w, w), (0, 0)],\n",
    "        mode=\"REFLECT\",\n",
    "        constant_values=constant_value,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'get_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-f48779b808c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.5/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m             if all([s is not None\n\u001b[1;32m    473\u001b[0m                     for s in to_list(input_shape)]):\n\u001b[0;32m--> 474\u001b[0;31m                 \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.5/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    650\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_elem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx_elem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m             \u001b[0;31m# Otherwise, we default to the input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             warnings.warn('`output_shape` argument not specified for layer {} '\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mint_shape\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'get_shape'"
     ]
    }
   ],
   "source": [
    "#def mean(x):\n",
    "#    return K.mean(x, axis=1, keepdims=True)\n",
    "#model.add(Lambda(mean, output_shape=output_of_lambda))\n",
    "#view raw\n",
    "\n",
    "def pad(x):\n",
    "    w = 0\n",
    "    mode=\"REFLECT\"\n",
    "    constant_value=0.5\n",
    "    if constant_value == \"uniform\":\n",
    "        constant_value_ = tf.random_uniform([], 0, 1)\n",
    "    else:\n",
    "        constant_value_ = constant_value\n",
    "    return tf.pad(\n",
    "        x,\n",
    "        [(0, 0), (w, w), (w, w), (0, 0)],\n",
    "        mode=mode,\n",
    "        constant_values=constant_value_,\n",
    "    )\n",
    "def maximum(x):\n",
    "    return K.max(x,axis=1,keepdims=True)\n",
    "#predictions = Lambda(maximum,name=\"max\")(concat)\n",
    "\n",
    "#画像をmodifyするモデルをつくって最初のモデルの上にのっける\n",
    "from keras.layers import Input,Lambda\n",
    "from keras import Model,Sequential\n",
    "\n",
    "input_tensor = Input(shape=(224, 224, 3))\n",
    "l = Lambda(lambda x: pad)(input_tensor)\n",
    "model2 = Model(inputs=input_tensor,outputs=l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras import Model\n",
    "def _compute_gradients(tensor, var_list):\n",
    "    grads = tf.gradients(tensor, var_list)\n",
    "    return [grad if grad is not None else tf.zeros_like(var)\n",
    "          for var, grad in zip(var_list, grads)]\n",
    "\n",
    "import tensorflow as tf\n",
    "#https://github.com/tensorflow/lucid/blob/master/lucid/optvis/transform.py\n",
    "\n",
    "\n",
    "\n",
    "def visualize_filter(model,layer_name, filter_index, steps=100):\n",
    "    def _deprocess_image(x):\n",
    "        # normalize tensor: center on 0., ensure std is 0.1\n",
    "        x -= x.mean()\n",
    "        x /= (x.std() + 1e-5)\n",
    "        x *= 0.1\n",
    "\n",
    "        # clip to [0, 1]\n",
    "        x += 0.5\n",
    "        x = np.clip(x, 0, 1)\n",
    "\n",
    "        # convert to RGB array\n",
    "        x *= 255\n",
    "        #x = x.transpose((1, 2, 0))\n",
    "        x = np.clip(x, 0, 255).astype('uint8')\n",
    "        return x\n",
    "\n",
    "    input_tensor = Input(shape=(224, 224, 3))\n",
    "    #input_tensor = model.input\n",
    "    #modified = pseudo(input_tensor)\n",
    "    #input_tensor = random_rotate(input_tensor,list(range(-10, 11)) + 5 * [0])\n",
    "    #input_tensor = pad(input_tensor,0)\n",
    "    #input_tensor = jitter(input_tensor,8)\n",
    "    print(input_tensor)\n",
    "    \n",
    "    layer_dict = OrderedDict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    \n",
    "    if layer_name == 'predictions':\n",
    "        activation = K.mean(layer_output[:, filter_index])\n",
    "    else:\n",
    "        activation = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "    grads = K.gradients(activation, input_tensor)[0]\n",
    "    #grads = _compute_gradients(activation, input_tensor)[0]\n",
    "    grads /= (K.sqrt(K.mean(K.square(grads))) + K.epsilon())\n",
    "    iterate = K.function([input_tensor], [activation, grads])\n",
    "\n",
    "    # ノイズを含んだ画像（4Dテンソル）から開始する\n",
    "    x = np.random.random((1, 224, 224, 3))\n",
    "    x = (x - 0.5) * 20 + 128\n",
    "\n",
    "    # 勾配法で層の出力（activation_value）を最大化するように入力画像を更新する\n",
    "    cache = None\n",
    "    for i in range(steps+1):\n",
    "        activation_value, grads_value = iterate([x])\n",
    "        # activation_valueを大きくしたいので画像に勾配を加える\n",
    "        #step, cache = rmsprop(grads_value, cache)\n",
    "        #x += step\n",
    "        x += grads_value\n",
    "        #print(i, activation_value)\n",
    "\n",
    "    # 画像に戻す\n",
    "    img = _deprocess_image(x[0])\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1_1:0\", shape=(?, 224, 224, 3), dtype=float32) Tensor(\"MirrorPad_16:0\", shape=(?, 224, 224, 3), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tried to convert 'x' to a tensor and failed. Error: None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    511\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    216\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    195\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 196\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    197\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"None values not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m     \u001b[0;31m# if dtype is provided, forces numpy array to be the type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: None values not supported.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    523\u001b[0m               observed = ops.internal_convert_to_tensor(\n\u001b[0;32m--> 524\u001b[0;31m                   values, as_ref=input_arg.is_ref).dtype.name\n\u001b[0m\u001b[1;32m    525\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    216\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    195\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 196\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    197\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"None values not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m     \u001b[0;31m# if dtype is provided, forces numpy array to be the type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: None values not supported.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-fafda171dafe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisualize_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"predictions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-142-b853d0a9071b>\u001b[0m in \u001b[0;36mvisualize_filter\u001b[0;34m(model, layer_name, filter_index, steps)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodified\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m#grads = _compute_gradients(activation, input_tensor)[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0miterate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msquare\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m     \"\"\"\n\u001b[0;32m-> 1450\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36msquare\u001b[0;34m(x, name)\u001b[0m\n\u001b[1;32m    340\u001b[0m           indices=x.indices, values=x_square, dense_shape=x.dense_shape)\n\u001b[1;32m    341\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36msquare\u001b[0;34m(x, name)\u001b[0m\n\u001b[1;32m   8066\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8067\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 8068\u001b[0;31m         \"Square\", x=x, name=name)\n\u001b[0m\u001b[1;32m   8069\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8070\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    526\u001b[0m               raise ValueError(\n\u001b[1;32m    527\u001b[0m                   \u001b[0;34m\"Tried to convert '%s' to a tensor and failed. Error: %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m                   (input_name, err))\n\u001b[0m\u001b[1;32m    529\u001b[0m             prefix = (\"Input '%s' of '%s' Op has type %s that does not match\" %\n\u001b[1;32m    530\u001b[0m                       (input_name, op_type_name, observed))\n",
      "\u001b[0;31mValueError\u001b[0m: Tried to convert 'x' to a tensor and failed. Error: None values not supported."
     ]
    }
   ],
   "source": [
    "img = visualize_filter(lmodel,\"predictions\",0,steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.shape)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_keras)",
   "language": "python",
   "name": "conda_keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
